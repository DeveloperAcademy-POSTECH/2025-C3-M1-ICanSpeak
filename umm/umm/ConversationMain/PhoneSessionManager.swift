//
//  PhoneSessionManager.swift
//  Plz
//
//  Created by Ella's Mac on 5/30/25.
//
import Foundation
import WatchConnectivity
import Speech
import BackgroundTasks
import AVFoundation

class PhoneSessionManager: NSObject, WCSessionDelegate, ObservableObject {
    static let shared = PhoneSessionManager()
    
    @Published var startTime: String = ""
    @Published var exitTime: String = ""
    @Published var receivedSuggestions: [WordSuggestion] = []
    @Published var conversationSessions: [ConversationSession] = []
    
    private let speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "ko-KR"))
    private var recognitionTask: SFSpeechRecognitionTask?
    
    // í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì„¸ì…˜
    private var currentSession: ConversationSession?
    
    private override init() {
        super.init()
        setupSpeechRecognition()
        activateSession()
        registerBackgroundTask()
        loadSavedSessions()
    }
    
    private func setupSpeechRecognition() {
        SFSpeechRecognizer.requestAuthorization { authStatus in
            switch authStatus {
            case .authorized:
                print("âœ… ìŒì„±ì¸ì‹ ê¶Œí•œ ìŠ¹ì¸ë¨")
            case .denied, .restricted, .notDetermined:
                print("âŒ ìŒì„±ì¸ì‹ ê¶Œí•œ ê±°ë¶€ë¨")
            @unknown default:
                break
            }
        }
    }
    
    private func activateSession() {
        if WCSession.isSupported() {
            let session = WCSession.default
            session.delegate = self  // âœ… í•˜ë‚˜ì˜ delegateë¡œ í†µí•©
            session.activate()
        }
    }
    
    // ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ë“±ë¡
    private func registerBackgroundTask() {
        BGTaskScheduler.shared.register(forTaskWithIdentifier: "com.yourapp.audioprocessing", using: nil) { task in
            self.handleBackgroundAudioProcessing(task: task as! BGProcessingTask)
        }
    }
    
    // MARK: - WCSessionDelegate êµ¬í˜„
    
    func session(_ session: WCSession, activationDidCompleteWith activationState: WCSessionActivationState, error: Error?) {
        print("âœ… WCSession í™œì„±í™” ì™„ë£Œ. ìƒíƒœ: \(activationState.rawValue)")
    }
    
    func sessionDidBecomeInactive(_ session: WCSession) {
        print("ğŸ”„ ì„¸ì…˜ ë¹„í™œì„±í™”ë¨")
    }
    
    func sessionDidDeactivate(_ session: WCSession) {
        print("ğŸ›‘ ì„¸ì…˜ ì¢…ë£Œë¨. ìƒˆë¡œìš´ ì„¸ì…˜ í™œì„±í™” ê°€ëŠ¥")
        WCSession.default.activate()
    }
    
    // âœ… í†µí•©ëœ ë©”ì‹œì§€ ìˆ˜ì‹  ì²˜ë¦¬ (Reply Handler ìˆëŠ” ë²„ì „)
    func session(_ session: WCSession, didReceiveMessage message: [String : Any], replyHandler: @escaping ([String : Any]) -> Void) {
        print("ğŸ“¨ [Manager] ë©”ì‹œì§€ ìˆ˜ì‹ : \(message)")
        
        // ì˜¤ë””ì˜¤ ë°ì´í„° ì¦‰ì‹œ ì²˜ë¦¬
        if let audioData = message["audioData"] as? Data,
           message["needsImmediateProcessing"] as? Bool == true {
            print("ğŸ“¥ ì¦‰ì‹œ ì²˜ë¦¬ìš© ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹ ë¨")
            
            processAudioData(audioData) { recognizedText in
                let response = ["recognizedText": recognizedText]
                replyHandler(response)
                print("âœ… ì¦‰ì‹œ ì²˜ë¦¬ ì™„ë£Œ: \(recognizedText)")
            }
            return
        }
        
        // ì‹œê°„ ë° ì œì•ˆ ë©”ì‹œì§€ ì²˜ë¦¬
        DispatchQueue.main.async {
            // ì‹œì‘ ì‹œê°„ ì²˜ë¦¬
            if let startTimeString = message["startTime"] as? String {
                self.startTime = startTimeString
                self.handleStartTime(startTimeString)
                print("âœ… ë°›ì€ startTime: \(startTimeString)")
            }
            
            // ì¢…ë£Œ ì‹œê°„ ì²˜ë¦¬
            if let exitTimeString = message["exitTime"] as? String {
                self.exitTime = exitTimeString
                self.handleExitTime(exitTimeString)
                print("âœ… ë°›ì€ exitTime: \(exitTimeString)")
            }
            
            // WordSuggestion ë°°ì—´ ì²˜ë¦¬
            if let data = message["suggestions"] as? Data,
               let decoded = try? JSONDecoder().decode([WordSuggestion].self, from: data) {
                let keyword = message["keyword"] as? String
                self.handleReceivedSuggestions(decoded, keyword: keyword ?? "ì•Œ ìˆ˜ ì—†ìŒ")
            }
        }
        
        replyHandler([:])
    }
    
    // âœ… í†µí•©ëœ ë©”ì‹œì§€ ìˆ˜ì‹  ì²˜ë¦¬ (Reply Handler ì—†ëŠ” ë²„ì „)
    func session(_ session: WCSession, didReceiveMessage message: [String: Any]) {
        print("ğŸ“¨ [Manager - NoReply] ë©”ì‹œì§€ ìˆ˜ì‹ : \(message)")

        DispatchQueue.main.async {
            // ì‹œì‘ ì‹œê°„ ì²˜ë¦¬
            if let startTimeString = message["startTime"] as? String {
                self.startTime = startTimeString
                self.handleStartTime(startTimeString)
                print("âœ… ë°›ì€ startTime (noReply): \(startTimeString)")
            }
            
            // ì¢…ë£Œ ì‹œê°„ ì²˜ë¦¬
            if let exitTimeString = message["exitTime"] as? String {
                self.exitTime = exitTimeString
                self.handleExitTime(exitTimeString)
                print("âœ… ë°›ì€ exitTime (noReply): \(exitTimeString)")
            }
            
            // WordSuggestion ë°°ì—´ ì²˜ë¦¬
            if let data = message["suggestions"] as? Data,
               let decoded = try? JSONDecoder().decode([WordSuggestion].self, from: data) {
                let keyword = message["keyword"] as? String
                self.handleReceivedSuggestions(decoded, keyword: keyword ?? "ì•Œ ìˆ˜ ì—†ìŒ")
            }
        }
    }
    
    // âœ… ë°±ê·¸ë¼ìš´ë“œ íŒŒì¼ ìˆ˜ì‹  ì²˜ë¦¬
    func session(_ session: WCSession, didReceive file: WCSessionFile) {
        print("ğŸ“¥ ë°±ê·¸ë¼ìš´ë“œ íŒŒì¼ ìˆ˜ì‹ ë¨: \(file.fileURL.lastPathComponent)")
        
        let sourceURL = file.fileURL
        let destinationURL = FileManager.default.temporaryDirectory.appendingPathComponent("receivedAudio_\(UUID().uuidString).m4a")
        
        do {
            try FileManager.default.copyItem(at: sourceURL, to: destinationURL)
            print("ğŸ“¥ ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ ì™„ë£Œ: \(destinationURL.lastPathComponent)")
            
            DispatchQueue.global(qos: .userInitiated).async {
                do {
                    let audioData = try Data(contentsOf: destinationURL)
                    self.processAudioData(audioData) { recognizedText in
                        DispatchQueue.main.async {
                            self.sendTextToWatch(recognizedText)
                        }
                        try? FileManager.default.removeItem(at: destinationURL)
                    }
                } catch {
                    print("âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: \(error)")
                }
            }
            
        } catch {
            print("âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: \(error.localizedDescription)")
        }
    }
    
    // MARK: - ëŒ€í™” ì„¸ì…˜ ê´€ë¦¬ (ê¸°ì¡´ PhoneMessageReceiver ê¸°ëŠ¥ í†µí•©)
    
    // ì‹œì‘ ì‹œê°„ ì²˜ë¦¬ - ìƒˆë¡œìš´ ConversationSession ì‹œì‘
    private func handleStartTime(_ startTimeString: String) {
        let formatter = ISO8601DateFormatter()
        guard let startTime = formatter.date(from: startTimeString) else {
            print("âŒ ì‹œì‘ ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨: \(startTimeString)")
            return
        }
        
        // ìƒˆë¡œìš´ ì„¸ì…˜ ì‹œì‘
        currentSession = ConversationSession(
            startTime: startTime,
            endTime: nil,
            groups: []
        )
        
        print("âœ… ìƒˆë¡œìš´ ëŒ€í™” ì„¸ì…˜ ì‹œì‘: \(startTime)")
    }
    
    // ì¢…ë£Œ ì‹œê°„ ì²˜ë¦¬ - í˜„ì¬ ì„¸ì…˜ ì™„ë£Œ
    private func handleExitTime(_ exitTimeString: String) {
        let formatter = ISO8601DateFormatter()
        guard let exitTime = formatter.date(from: exitTimeString),
              var session = currentSession else {
            print("âŒ ì¢…ë£Œ ì‹œê°„ ì²˜ë¦¬ ì‹¤íŒ¨")
            return
        }
        
        // í˜„ì¬ ì„¸ì…˜ì— ì¢…ë£Œ ì‹œê°„ ì„¤ì •
        session.endTime = exitTime
        
        // ì™„ë£Œëœ ì„¸ì…˜ì„ ë°°ì—´ì— ì¶”ê°€ (ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬)
        conversationSessions.insert(session, at: 0)
        
        // í˜„ì¬ ì„¸ì…˜ ì´ˆê¸°í™”
        currentSession = nil
        
        // ì €ì¥
        saveSessions()
        
        print("âœ… ëŒ€í™” ì„¸ì…˜ ì™„ë£Œ: \(session.startTime) ~ \(exitTime)")
        print("ì´ ê·¸ë£¹ ìˆ˜: \(session.groups.count)")
    }
    
    // WordSuggestion ë°°ì—´ì„ ë°›ì•„ì„œ í˜„ì¬ ì„¸ì…˜ì— ê·¸ë£¹ìœ¼ë¡œ ì¶”ê°€
    private func handleReceivedSuggestions(_ suggestions: [WordSuggestion], keyword: String) {
        guard !suggestions.isEmpty else { return }
        
        // í˜„ì¬ ì„¸ì…˜ì´ ì—†ìœ¼ë©´ ì„ì‹œë¡œ ìƒì„± (í˜¹ì‹œ ì‹œì‘ ë©”ì‹œì§€ë¥¼ ë†“ì¹œ ê²½ìš°)
        if currentSession == nil {
            currentSession = ConversationSession(
                startTime: Date(),
                endTime: nil,
                groups: []
            )
            print("âš ï¸ ì‹œì‘ ë©”ì‹œì§€ ì—†ì´ ì œì•ˆ ìˆ˜ì‹ , ì„ì‹œ ì„¸ì…˜ ìƒì„±")
        }
        
        let newGroup = WordSuggestionGroup(
            keyword: keyword,
            suggestions: suggestions
        )
        
        currentSession?.groups.append(newGroup)
        
        // UI ì—…ë°ì´íŠ¸ìš©
        receivedSuggestions = suggestions
        
        print("ğŸ“¥ ê·¸ë£¹ ì¶”ê°€ë¨ - í‚¤ì›Œë“œ: \(keyword), ì œì•ˆ ìˆ˜: \(suggestions.count)")
    }
    
    // MARK: - ì„¸ì…˜ ë°ì´í„° ê´€ë¦¬
    
    // ì„¸ì…˜ ì €ì¥
    private func saveSessions() {
        if let encoded = try? JSONEncoder().encode(conversationSessions) {
            UserDefaults.standard.set(encoded, forKey: "ConversationSessions")
        }
    }
    
    // ì €ì¥ëœ ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸°
    private func loadSavedSessions() {
        if let data = UserDefaults.standard.data(forKey: "ConversationSessions"),
           let decoded = try? JSONDecoder().decode([ConversationSession].self, from: data) {
            conversationSessions = decoded
        }
    }
    
    // ì„¸ì…˜ ì‚­ì œ
    func deleteSession(at indexSet: IndexSet) {
        conversationSessions.remove(atOffsets: indexSet)
        saveSessions()
    }
    
  func deleteGroup(withId groupId: UUID) {
    for index in conversationSessions.indices {
      if let groupIndex = conversationSessions[index].groups.firstIndex(where: { $0.id == groupId }) {
        conversationSessions[index].groups.remove(at: groupIndex)
        // ì„¸ì…˜ì´ ë¹„ì–´ ìˆìœ¼ë©´ ì œê±°
        if conversationSessions[index].groups.isEmpty {
          conversationSessions.remove(at: index)}
        saveSessions()
        break
      }
    }
  }
  
    // MARK: - ìŒì„± ì¸ì‹ ì²˜ë¦¬
    
    // âœ… í•µì‹¬ ìŒì„± ì¸ì‹ ì²˜ë¦¬ ë¡œì§
    private func processAudioData(_ audioData: Data, completion: @escaping (String) -> Void) {
        guard let speechRecognizer = speechRecognizer, speechRecognizer.isAvailable else {
            completion("ìŒì„±ì¸ì‹ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
        }

        do {
            let tempURL = FileManager.default.temporaryDirectory.appendingPathComponent("temp_audio_\(UUID().uuidString).m4a")
            try audioData.write(to: tempURL)

            let request = SFSpeechURLRecognitionRequest(url: tempURL)
            request.shouldReportPartialResults = false
            request.requiresOnDeviceRecognition = false

            var hasCompleted = false // âœ… ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€

            recognitionTask = speechRecognizer.recognitionTask(with: request) { result, error in
                defer {
                    try? FileManager.default.removeItem(at: tempURL)
                }

                guard !hasCompleted else { return }

                if let result = result, result.isFinal {
                    hasCompleted = true
                    completion(result.bestTranscription.formattedString)
                } else if let error = error {
                    hasCompleted = true
                    print("âŒ ìŒì„±ì¸ì‹ ì˜¤ë¥˜: \(error)")
                    completion("ìŒì„±ì¸ì‹ ì‹¤íŒ¨")
                } else if let result = result {
                    hasCompleted = true
                    completion(result.bestTranscription.formattedString)
                }
            }

        } catch {
            print("âŒ ì„ì‹œ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: \(error)")
            completion("íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨")
        }
    }
    
    // MARK: - Watch í†µì‹ 
    
    func sendTextToWatch(_ text: String) {
        print("ğŸ“¡ Watch ì—°ê²° ìƒíƒœ: \(WCSession.default.isReachable)")

        if WCSession.default.isReachable {
            WCSession.default.sendMessage(["recognizedText": text], replyHandler: nil) { error in
                print("âŒ í…ìŠ¤íŠ¸ ì „ì†¡ ì‹¤íŒ¨: \(error.localizedDescription)")
                self.sendViaContext(text: text)
            }
            print("ğŸ“¤ í…ìŠ¤íŠ¸ ì „ì†¡ ì™„ë£Œ: \(text)")
        } else {
            print("âš ï¸ Watchì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Contextë¡œ ì „ì†¡í•©ë‹ˆë‹¤.")
            sendViaContext(text: text)
        }
    }
    
    private func sendViaContext(text: String) {
        do {
            try WCSession.default.updateApplicationContext(["recognizedText": text])
            print("ğŸ“¤ Contextë¡œ ì „ì†¡ë¨: \(text)")
        } catch {
            print("âŒ Context ì „ì†¡ ì‹¤íŒ¨: \(error)")
        }
    }
    
    // MARK: - ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬
    
    private func handleBackgroundAudioProcessing(task: BGProcessingTask) {
        task.expirationHandler = {
            task.setTaskCompleted(success: false)
        }
        
        processPendingAudioFiles { success in
            task.setTaskCompleted(success: success)
        }
    }
    
    private func processPendingAudioFiles(completion: @escaping (Bool) -> Void) {
        let tempDir = FileManager.default.temporaryDirectory
        
        do {
            let files = try FileManager.default.contentsOfDirectory(at: tempDir, includingPropertiesForKeys: nil)
            let audioFiles = files.filter { $0.pathExtension == "m4a" && $0.lastPathComponent.contains("receivedAudio") }
            
            if audioFiles.isEmpty {
                completion(true)
                return
            }
            
            let group = DispatchGroup()
            var allSuccess = true
            
            for audioFile in audioFiles {
                group.enter()
                do {
                    let audioData = try Data(contentsOf: audioFile)
                    processAudioData(audioData) { recognizedText in
                        self.sendTextToWatch(recognizedText)
                        try? FileManager.default.removeItem(at: audioFile)
                        group.leave()
                    }
                } catch {
                    print("âŒ ë°±ê·¸ë¼ìš´ë“œ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: \(error)")
                    allSuccess = false
                    group.leave()
                }
            }
            
            group.notify(queue: .main) {
                completion(allSuccess)
            }
            
        } catch {
            print("âŒ ì„ì‹œ ë””ë ‰í† ë¦¬ í™•ì¸ ì‹¤íŒ¨: \(error)")
            completion(false)
        }
    }
    
    // MARK: - ê¸°ì¡´ í˜¸í™˜ì„± ë©”ì„œë“œ
    
    func recognizeSpeech(from url: URL) {
        do {
            let audioData = try Data(contentsOf: url)
            processAudioData(audioData) { recognizedText in
                self.sendTextToWatch(recognizedText)
            }
        } catch {
            print("âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: \(error)")
        }
    }
}
