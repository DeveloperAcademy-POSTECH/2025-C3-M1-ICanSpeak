//
//  PhoneSessionManager.swift
//  Plz
//
//  Created by Ella's Mac on 5/30/25.
//
import Foundation
import WatchConnectivity
import Speech
import BackgroundTasks
import AVFoundation

class PhoneSessionManager: NSObject, WCSessionDelegate, ObservableObject {
    static let shared = PhoneSessionManager()
  
    @Published var startTime: String = ""
    @Published var exitTime: String = ""
    
    private let speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "ko-KR"))
    private var recognitionTask: SFSpeechRecognitionTask?
    
    private override init() {
        super.init()
        setupSpeechRecognition()
        activateSession()
        registerBackgroundTask()
    }
    
    private func setupSpeechRecognition() {
        SFSpeechRecognizer.requestAuthorization { authStatus in
            switch authStatus {
            case .authorized:
                print("âœ… ìŒì„±ì¸ì‹ ê¶Œí•œ ìŠ¹ì¸ë¨")
            case .denied, .restricted, .notDetermined:
                print("âŒ ìŒì„±ì¸ì‹ ê¶Œí•œ ê±°ë¶€ë¨")
            @unknown default:
                break
            }
        }
    }
    
    private func activateSession() {
        if WCSession.isSupported() {
            let session = WCSession.default
            session.delegate = self
            session.activate()
        }
    }
    
    // ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ë“±ë¡
    private func registerBackgroundTask() {
        BGTaskScheduler.shared.register(forTaskWithIdentifier: "com.yourapp.audioprocessing", using: nil) { task in
            self.handleBackgroundAudioProcessing(task: task as! BGProcessingTask)
        }
    }
    
    func session(_ session: WCSession, activationDidCompleteWith activationState: WCSessionActivationState, error: Error?) {
        print("âœ… WCSession í™œì„±í™” ì™„ë£Œ. ìƒíƒœ: \(activationState.rawValue)")
    }
    
    func sessionDidBecomeInactive(_ session: WCSession) {
        print("ğŸ”„ ì„¸ì…˜ ë¹„í™œì„±í™”ë¨")
    }
    
    func sessionDidDeactivate(_ session: WCSession) {
        print("ğŸ›‘ ì„¸ì…˜ ì¢…ë£Œë¨. ìƒˆë¡œìš´ ì„¸ì…˜ í™œì„±í™” ê°€ëŠ¥")
        WCSession.default.activate()
    }
    
    // âœ… ì¦‰ì‹œ ì²˜ë¦¬ìš© ë©”ì‹œì§€ ìˆ˜ì‹  (ì•„ì´í° í¬ê·¸ë¼ìš´ë“œì¼ ë•Œ)
    func session(_ session: WCSession, didReceiveMessage message: [String : Any], replyHandler: @escaping ([String : Any]) -> Void) {
        
        // ì˜¤ë””ì˜¤ ë°ì´í„° ì¦‰ì‹œ ì²˜ë¦¬
        if let audioData = message["audioData"] as? Data,
           message["needsImmediateProcessing"] as? Bool == true {
            
            print("ğŸ“¥ ì¦‰ì‹œ ì²˜ë¦¬ìš© ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹ ë¨")
            
            processAudioData(audioData) { [weak self] recognizedText in
                let response = ["recognizedText": recognizedText]
                replyHandler(response)
                print("âœ… ì¦‰ì‹œ ì²˜ë¦¬ ì™„ë£Œ: \(recognizedText)")
            }
            return
        }
        
        // ê¸°ì¡´ ì‹œê°„ ë©”ì‹œì§€ ì²˜ë¦¬
        DispatchQueue.main.async {
            if let startTime = message["startTime"] as? String {
                self.startTime = startTime
                print("âœ… ë°›ì€ startTime: \(startTime)")
            } else if let exitTime = message["exitTime"] as? String {
                self.exitTime = exitTime
                print("âœ… ë°›ì€ exitTime: \(exitTime)")
            }
        }
        
        replyHandler([:])
    }
    
    // âœ… ë°±ê·¸ë¼ìš´ë“œ íŒŒì¼ ìˆ˜ì‹  ì²˜ë¦¬ (ì•„ì´í° ë°±ê·¸ë¼ìš´ë“œì¼ ë•Œ)
    func session(_ session: WCSession, didReceive file: WCSessionFile) {
        print("ğŸ“¥ ë°±ê·¸ë¼ìš´ë“œ íŒŒì¼ ìˆ˜ì‹ ë¨: \(file.fileURL.lastPathComponent)")
        
        let sourceURL = file.fileURL
        let destinationURL = FileManager.default.temporaryDirectory.appendingPathComponent("receivedAudio_\(UUID().uuidString).m4a")
        
        do {
            try FileManager.default.copyItem(at: sourceURL, to: destinationURL)
            print("ğŸ“¥ ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ ì™„ë£Œ: \(destinationURL.lastPathComponent)")
            
            // ë°±ê·¸ë¼ìš´ë“œì—ì„œë„ ì²˜ë¦¬ ê°€ëŠ¥í•˜ë„ë¡
            DispatchQueue.global(qos: .userInitiated).async {
                do {
                    let audioData = try Data(contentsOf: destinationURL)
                    self.processAudioData(audioData) { recognizedText in
                        DispatchQueue.main.async {
                            self.sendTextToWatch(recognizedText)
                        }
                        
                        // ì„ì‹œ íŒŒì¼ ì‚­ì œ
                        try? FileManager.default.removeItem(at: destinationURL)
                    }
                } catch {
                    print("âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: \(error)")
                }
            }
            
        } catch {
            print("âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: \(error.localizedDescription)")
        }
    }
    
    // ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì²˜ë¦¬
    private func handleBackgroundAudioProcessing(task: BGProcessingTask) {
        task.expirationHandler = {
            task.setTaskCompleted(success: false)
        }
        
        // ëŒ€ê¸° ì¤‘ì¸ ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ ì²˜ë¦¬
        processPendingAudioFiles { success in
            task.setTaskCompleted(success: success)
        }
    }
    
    // âœ… í•µì‹¬ ìŒì„± ì¸ì‹ ì²˜ë¦¬ ë¡œì§ (ë°±ê·¸ë¼ìš´ë“œì—ì„œë„ ì‘ë™)
    private func processAudioData(_ audioData: Data, completion: @escaping (String) -> Void) {
        guard let speechRecognizer = speechRecognizer, speechRecognizer.isAvailable else {
            completion("ìŒì„±ì¸ì‹ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
        }
        
        do {
            // ì„ì‹œ íŒŒì¼ ìƒì„±
            let tempURL = FileManager.default.temporaryDirectory.appendingPathComponent("temp_audio_\(UUID().uuidString).m4a")
            try audioData.write(to: tempURL)
            
            let request = SFSpeechURLRecognitionRequest(url: tempURL)
            request.shouldReportPartialResults = false
            request.requiresOnDeviceRecognition = false // ì˜¨ë¼ì¸ ì¸ì‹ ì‚¬ìš© (ë” ì •í™•í•¨)
            
            recognitionTask = speechRecognizer.recognitionTask(with: request) { result, error in
                defer {
                    // ì„ì‹œ íŒŒì¼ ì‚­ì œ
                    try? FileManager.default.removeItem(at: tempURL)
                }
                
                if let result = result, result.isFinal {
                    let recognizedText = result.bestTranscription.formattedString
                    completion(recognizedText)
                } else if let error = error {
                    print("âŒ ìŒì„±ì¸ì‹ ì˜¤ë¥˜: \(error)")
                    completion("ìŒì„±ì¸ì‹ ì‹¤íŒ¨")
                } else if let result = result {
                    // ìµœì¢… ê²°ê³¼ê°€ ì•„ì§ ì•ˆ ì™”ì§€ë§Œ ì¼ë‹¨ í˜„ì¬ ê²°ê³¼ ì‚¬ìš©
                    let recognizedText = result.bestTranscription.formattedString
                    completion(recognizedText)
                }
            }
            
        } catch {
            print("âŒ ì„ì‹œ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: \(error)")
            completion("íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨")
        }
    }
    
    func sendTextToWatch(_ text: String) {
        print("ğŸ“¡ Watch ì—°ê²° ìƒíƒœ: \(WCSession.default.isReachable)")

        if WCSession.default.isReachable {
            WCSession.default.sendMessage(["recognizedText": text], replyHandler: nil) { error in
                print("âŒ í…ìŠ¤íŠ¸ ì „ì†¡ ì‹¤íŒ¨: \(error.localizedDescription)")
                // ì‹¤íŒ¨í•˜ë©´ contextë¡œ ì¬ì‹œë„
                self.sendViaContext(text: text)
            }
            print("ğŸ“¤ í…ìŠ¤íŠ¸ ì „ì†¡ ì™„ë£Œ: \(text)")
        } else {
            print("âš ï¸ Watchì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Contextë¡œ ì „ì†¡í•©ë‹ˆë‹¤.")
            sendViaContext(text: text)
        }
    }
    
    // Contextë¡œ ì „ì†¡ (ì—°ê²°ì´ ëŠì–´ì ¸ë„ ë‚˜ì¤‘ì— ì „ë‹¬ë¨)
    private func sendViaContext(text: String) {
        do {
            let context = ["recognizedText": text]
            try WCSession.default.updateApplicationContext(context)
            print("ğŸ“¤ Contextë¡œ ê²°ê³¼ ì „ì†¡ë¨: \(text)")
        } catch {
            print("âŒ Context ì „ì†¡ ì‹¤íŒ¨: \(error)")
        }
    }
    
    // ëŒ€ê¸° ì¤‘ì¸ íŒŒì¼ë“¤ ì²˜ë¦¬ (ë°±ê·¸ë¼ìš´ë“œìš©)
    private func processPendingAudioFiles(completion: @escaping (Bool) -> Void) {
        // ì„ì‹œ ë””ë ‰í† ë¦¬ì—ì„œ ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ ì°¾ê¸°
        let tempDir = FileManager.default.temporaryDirectory
        do {
            let files = try FileManager.default.contentsOfDirectory(at: tempDir, includingPropertiesForKeys: nil)
            let audioFiles = files.filter { $0.pathExtension == "m4a" && $0.lastPathComponent.contains("receivedAudio") }
            
            if audioFiles.isEmpty {
                completion(true)
                return
            }
            
            let group = DispatchGroup()
            var allSuccess = true
            
            for audioFile in audioFiles {
                group.enter()
                do {
                    let audioData = try Data(contentsOf: audioFile)
                    processAudioData(audioData) { recognizedText in
                        self.sendTextToWatch(recognizedText)
                        try? FileManager.default.removeItem(at: audioFile)
                        group.leave()
                    }
                } catch {
                    print("âŒ ë°±ê·¸ë¼ìš´ë“œ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: \(error)")
                    allSuccess = false
                    group.leave()
                }
            }
            
            group.notify(queue: .main) {
                completion(allSuccess)
            }
            
        } catch {
            print("âŒ ì„ì‹œ ë””ë ‰í† ë¦¬ í™•ì¸ ì‹¤íŒ¨: \(error)")
            completion(false)
        }
    }
    
    // âœ… ê¸°ì¡´ ë©”ì„œë“œë“¤ (í˜¸í™˜ì„± ìœ ì§€)
    func recognizeSpeech(from url: URL) {
        do {
            let audioData = try Data(contentsOf: url)
            processAudioData(audioData) { recognizedText in
                self.sendTextToWatch(recognizedText)
            }
        } catch {
            print("âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: \(error)")
        }
    }
}
